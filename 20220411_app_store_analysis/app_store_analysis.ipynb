{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Mobile Apps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Functional Goal**: We are interested in apps with a maximal number of users. We assume that all apps are free to download, and generate income based on the size of its userbase.\n",
    "\n",
    "In this analysis, we use datasets from the App Store and Google Play to better understand which genres have a larger number of users.\n",
    "\n",
    "**Datasets**: \n",
    "* A sampling of 10,000 Android apps from Google Play; collected on August 2018. [Link to download .csv file](https://dq-content.s3.amazonaws.com/350/googleplaystore.csv).\n",
    "* A sampling of 7,000 iOS apps from the App Store; collected on July 2017. [Link to download .csv file](https://dq-content.s3.amazonaws.com/350/AppleStore.csv)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entirety of this analysis was done **sans Pandas**. Instead, the datasets were analyzed using pure Python and bespoke functions, with a touch of help from very common packages. Let's begin by reading in the datasets and importing some basic libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to repeatedly load in datasets, and convert them to a list-of-lists for easier, iterative analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_data(dataset, headers=True):\n",
    "    '''\n",
    "    A function to convert .csv files to a list-of-lists.\n",
    "\n",
    "    Args:\n",
    "        dataset (str): Relative path to a dataset in .csv format.\n",
    "        headers (bool): Function returns first row of dataset, by default. Set to \"False\" to return only row with index 1 and higher.\n",
    "        \n",
    "    Dependencies:\n",
    "        import csv\n",
    "\n",
    "    Returns:\n",
    "        multi_list (list): A list of lists.\n",
    "    '''\n",
    "    opened_file = open(dataset, encoding='utf8')\n",
    "    read_file = csv.reader(opened_file)\n",
    "    apps_data = list(read_file)\n",
    "\n",
    "    if headers:\n",
    "        return apps_data\n",
    "    else:\n",
    "        return apps_data[1:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the data and save the list-of-lists to separate variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "android = open_data('./../googleplaystore.csv')\n",
    "apple = open_data('./../AppleStore.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function for creating a data overview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_data(dataset, start, end, rows_and_columns=False):\n",
    "    '''\n",
    "    A function to look at a subset of rows in a list of lists.\n",
    "\n",
    "    Args:\n",
    "        dataset (list): A list of lists containing data. \n",
    "        start (int): The first row to include in a slice of the data view. \n",
    "        end (int): The last row to include in a slice of the data view. \n",
    "        rows_and_columns (bool): Return the number of rows and columns in a dataset? (y/n)\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    '''\n",
    "    dataset_slice = dataset[start:end]\n",
    "    for row in dataset_slice:\n",
    "        print(row)\n",
    "        print('\\n')\n",
    "    if rows_and_columns:\n",
    "        print(f\"Number of rows: {len(dataset)}\")\n",
    "        print(f\"Number of columns: {len(dataset[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['App', 'Category', 'Rating', 'Reviews', 'Size', 'Installs', 'Type', 'Price', 'Content Rating', 'Genres', 'Last Updated', 'Current Ver', 'Android Ver']\n",
      "\n",
      "\n",
      "['Photo Editor & Candy Camera & Grid & ScrapBook', 'ART_AND_DESIGN', '4.1', '159', '19M', '10,000+', 'Free', '0', 'Everyone', 'Art & Design', 'January 7, 2018', '1.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "['Coloring book moana', 'ART_AND_DESIGN', '3.9', '967', '14M', '500,000+', 'Free', '0', 'Everyone', 'Art & Design;Pretend Play', 'January 15, 2018', '2.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "Number of rows: 10842\n",
      "Number of columns: 13\n"
     ]
    }
   ],
   "source": [
    "explore_data(android, 0, 3, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'track_name', 'size_bytes', 'currency', 'price', 'rating_count_tot', 'rating_count_ver', 'user_rating', 'user_rating_ver', 'ver', 'cont_rating', 'prime_genre', 'sup_devices.num', 'ipadSc_urls.num', 'lang.num', 'vpp_lic']\n",
      "\n",
      "\n",
      "['284882215', 'Facebook', '389879808', 'USD', '0.0', '2974676', '212', '3.5', '3.5', '95.0', '4+', 'Social Networking', '37', '1', '29', '1']\n",
      "\n",
      "\n",
      "['389801252', 'Instagram', '113954816', 'USD', '0.0', '2161558', '1289', '4.5', '4.0', '10.23', '12+', 'Photo & Video', '37', '0', '29', '1']\n",
      "\n",
      "\n",
      "Number of rows: 7198\n",
      "Number of columns: 16\n"
     ]
    }
   ],
   "source": [
    "explore_data(apple, 0, 3, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goals: \n",
    "* Remove non-English apps.\n",
    "* Remove paid apps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the rows in the dataset may have an incorrect value, leading to a frameshift in the `ratings` column. See this [Kaggle post](https://www.kaggle.com/datasets/lava18/google-play-store-apps/discussion/66015) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TownWiFi | Wi-Fi Everywhere', 'COMMUNICATION', '3.9', '2372', '58M', '500,000+', 'Free', '0', 'Everyone', 'Communication', 'August 2, 2018', '4.2.1', '4.2 and up']\n",
      "\n",
      "\n",
      "['Jazz Wi-Fi', 'COMMUNICATION', '3.4', '49', '4.0M', '10,000+', 'Free', '0', 'Everyone', 'Communication', 'February 10, 2017', '0.1', '2.3 and up']\n",
      "\n",
      "\n",
      "['Xposed Wi-Fi-Pwd', 'PERSONALIZATION', '3.5', '1042', '404k', '100,000+', 'Free', '0', 'Everyone', 'Personalization', 'August 5, 2014', '3.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "['Life Made WI-Fi Touchscreen Photo Frame', '1.9', '19', '3.0M', '1,000+', 'Free', '0', 'Everyone', '', 'February 11, 2018', '1.0.19', '4.0 and up']\n",
      "\n",
      "\n",
      "['osmino Wi-Fi: free WiFi', 'TOOLS', '4.2', '134203', '4.1M', '10,000,000+', 'Free', '0', 'Everyone', 'Tools', 'August 7, 2018', '6.06.14', '4.4 and up']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "explore_data(android, 10470, 10475)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The index of the row with the error in the `android` dataset is 10473."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10841\n"
     ]
    }
   ],
   "source": [
    "if 'Life Made WI-Fi Touchscreen Photo Frame' in android[10473]:\n",
    "    del android[10473]\n",
    "    print(len(android))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some apps are also duplicated; take Instagram as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Instagram', 'SOCIAL', '4.5', '66577313', 'Varies with device', '1,000,000,000+', 'Free', '0', 'Teen', 'Social', 'July 31, 2018', 'Varies with device', 'Varies with device']\n",
      "['Instagram', 'SOCIAL', '4.5', '66577446', 'Varies with device', '1,000,000,000+', 'Free', '0', 'Teen', 'Social', 'July 31, 2018', 'Varies with device', 'Varies with device']\n",
      "['Instagram', 'SOCIAL', '4.5', '66577313', 'Varies with device', '1,000,000,000+', 'Free', '0', 'Teen', 'Social', 'July 31, 2018', 'Varies with device', 'Varies with device']\n",
      "['Instagram', 'SOCIAL', '4.5', '66509917', 'Varies with device', '1,000,000,000+', 'Free', '0', 'Teen', 'Social', 'July 31, 2018', 'Varies with device', 'Varies with device']\n"
     ]
    }
   ],
   "source": [
    "for app in android:\n",
    "    name = app[0]\n",
    "    if name == 'Instagram':\n",
    "        print(app)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at each of the duplicated Instagram entries, we notice something important: The column with index = 3 is the only bit that changes. This is the `ratings` column, and we can assume that the highest value here corresponds to the most recent data. In a future step, we will remove all duplicate entries, and keep only that row that has the highest number of reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of trying to find each app that is duplicated, though, we can write a function that iterates through the list, checks whether each app has already been viewed, and marks duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_apps = []\n",
    "unique_apps = []\n",
    "\n",
    "# Iterate through the dataset, but remove the header row. \n",
    "for app in android[1:]:\n",
    "    name = app[0]\n",
    "    if name in unique_apps:\n",
    "        duplicate_apps.append(name)\n",
    "    else:\n",
    "        unique_apps.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1181 duplicated apps.\n",
      "There are 9659 unique apps in the Android dataset.\n",
      "Examples of duplicate apps: ['Quick PDF Scanner + OCR FREE', 'Box', 'Google My Business', 'ZOOM Cloud Meetings', 'join.me - Simple Meetings', 'Box', 'Zenefits', 'Google Ads', 'Google My Business', 'Slack']\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {len(duplicate_apps)} duplicated apps.\")\n",
    "print(f\"There are {len(unique_apps)} unique apps in the Android dataset.\")\n",
    "print(f\"Examples of duplicate apps: {duplicate_apps[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function that detects whether an app is already in the dataset. Remove it unless it has the highest number of ratings out of all the duplicate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_unique_apps(dataset, name_column, value_column, print_results=False, header=True):\n",
    "    '''\n",
    "    A function that identifies unique values in a list-of-lists, and adds them to a dictionary.\n",
    "\n",
    "    Args:\n",
    "        dataset (list): A list of lists containing data. \n",
    "        name_column (int): The column name in which duplicates may appear (e.g. the list of app names in our example.)\n",
    "        value_column (int): The column to store as values, int, in the comparator dictionary (e.g. the number of ratings for each app in our example.)\n",
    "        print_results (bool): Print sentences displaying the before-and-after results? (y/n)\n",
    "        header (bool): If header is present, remove first row of dataset by default. If header is not present, continue.\n",
    "\n",
    "    Returns:\n",
    "        dataset (dict): A deduplicated dictionary with key:value pairs. The value is the highest value for the items with a given key in the initial dataset.\n",
    "    '''\n",
    "    reviews_max = {}\n",
    "\n",
    "    if header:\n",
    "        dataset = dataset[1:]\n",
    "\n",
    "    for row in dataset:\n",
    "        name = row[name_column]\n",
    "        n_reviews = float(row[value_column])\n",
    "\n",
    "        if name not in reviews_max:\n",
    "            reviews_max[name] = n_reviews\n",
    "        elif name in reviews_max and reviews_max[name] < n_reviews:\n",
    "            reviews_max[name] = n_reviews\n",
    "\n",
    "    if print_results:\n",
    "        print(f\"Length of initial dataset: {len(dataset)}\")\n",
    "        print(f\"Length of dataset with only unique apps: {len(reviews_max)}\")\n",
    "\n",
    "    return reviews_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of initial dataset: 7197\n",
      "Length of dataset with only unique apps: 7197\n",
      "Length of initial dataset: 10840\n",
      "Length of dataset with only unique apps: 9659\n"
     ]
    }
   ],
   "source": [
    "apple_uniques = find_unique_apps(apple, 0, 5, print_results=True)\n",
    "android_uniques = find_unique_apps(android, 0, 3, print_results=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our function has created a dictionary that contains key:value pairs corresponding to the name:no_of_ratings for each app in the Android and Apple datasets. Each key:value pair was replaced if, and only if, the same name appeared again with a higher number of ratings. Thus, we've retained those entries in which no_of_ratings was highest, as we are assuming that these correspond to the most recent app in the dataset.\n",
    "\n",
    "Note that the apple dataset did not have any duplicate values. Now that's clean!\n",
    "\n",
    "Now, I use these dictionaries to remove duplicate applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "STRATEGY\n",
    "\n",
    "Create an empty list. This will store our new list-of-lists with deduplicated values.\n",
    "Iterate through each row in the original list-of-lists. \n",
    "Store the name and no. of reviews for each row into a variable within the for loop. \n",
    "Check if the name is in the dictionary. If it is, check if the no. of reviews matches. \n",
    "If reviews match: Append the entire row, from the initial dataset, to the clean list. \n",
    "If reviews do not match: Continue \n",
    "Return the clean dataset. \n",
    "\"\"\"\n",
    "\n",
    "def deduplicate_data(dataset, unique_dict, index_1, index_2, print_results=False, header=True):\n",
    "    \"\"\"\n",
    "    A function that removes duplicate values from a list of lists, keeping only that row that has the highest value from a specified column.\n",
    "\n",
    "    Args:\n",
    "        dataset (list): A list of lists containing the original data with duplicated values. \n",
    "        unique_dict (dict): A dictionary containing the key:value pairs with unique values.\n",
    "        index_1 (int): The column used as keys in the unique_dict.\n",
    "        index_2 (int): The column used as values in the unique_dict.\n",
    "        print_results (bool): Print sentences displaying the before-and-after results.\n",
    "        header (bool): If header is present, remove first row of dataset by default. If header is not present, continue.\n",
    "\n",
    "    Returns:\n",
    "        clean_list (list): A list containing deduplicated rows.\n",
    "    \"\"\"\n",
    "    clean_list = []\n",
    "    already_added = []\n",
    "\n",
    "    if header:\n",
    "        dataset = dataset[1:]\n",
    "\n",
    "    for row in dataset:\n",
    "        name = row[index_1]\n",
    "        no_of_ratings = float(row[index_2])\n",
    "\n",
    "        if name in unique_dict and no_of_ratings == unique_dict[name] and name not in already_added:\n",
    "            clean_list.append(row)\n",
    "            already_added.append(name)\n",
    "\n",
    "    print(f\"Length of unique list: {len(already_added)}\")\n",
    "\n",
    "    if print_results:\n",
    "        print(f\"The length of clean_list is: {len(clean_list)}\")\n",
    "\n",
    "    return clean_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of unique list: 9659\n",
      "The length of clean_list is: 9659\n"
     ]
    }
   ],
   "source": [
    "android_clean = deduplicate_data(android, android_uniques, 0, 3, print_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Photo Editor & Candy Camera & Grid & ScrapBook', 'ART_AND_DESIGN', '4.1', '159', '19M', '10,000+', 'Free', '0', 'Everyone', 'Art & Design', 'January 7, 2018', '1.0.0', '4.0.3 and up']\n",
      "['id', 'track_name', 'size_bytes', 'currency', 'price', 'rating_count_tot', 'rating_count_ver', 'user_rating', 'user_rating_ver', 'ver', 'cont_rating', 'prime_genre', 'sup_devices.num', 'ipadSc_urls.num', 'lang.num', 'vpp_lic']\n"
     ]
    }
   ],
   "source": [
    "# The headers are not present in this dataset anymore. \n",
    "print(android_clean[0])\n",
    "print(apple[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple = apple[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove non-English apps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this phase, we'll use [ASCII](https://en.wikipedia.org/wiki/ASCII) criteria. English characters, like A->Z and 0->9, are all in the range of 0 to 127. If you execute the built-in `ord()` function on a character, you can see its ASCII value. Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n",
      "90\n",
      "53\n"
     ]
    }
   ],
   "source": [
    "print(ord('a'))\n",
    "print(ord('Z'))\n",
    "print(ord('5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a threshold. We shall iterate through our datasets and remove those apps that have more than **three** non-English characters in the name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_english(string, threshold=3):\n",
    "    \"\"\"\n",
    "    A function that checks whether a given string contains a non-English character. Tunable threshold.\n",
    "\n",
    "    Args:\n",
    "        string (str): The string to be checked.\n",
    "        threshold (int): The permittable number of non-English characters before an app is removed from the list.\n",
    "\n",
    "    Returns:\n",
    "        english_bool (bool): True or False, does the list contain all English characters. True if yes.\n",
    "    \"\"\"\n",
    "    counter = 0\n",
    "    for character in string:\n",
    "        if ord(character) > 127:\n",
    "            counter += 1\n",
    "\n",
    "    if counter > threshold:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the function on basic cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(is_english('Instagram'))\n",
    "print(is_english('爱奇艺PPS -《欢乐颂2》电视剧热播'))\n",
    "print(is_english('Docs To Go™ Free Office Suite'))\n",
    "print(is_english('Instachat 😜'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we iterate through each dataset and remove each non-English app using the custom function, `is_english`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_english_apps(dataset, index_col, header=False):\n",
    "    \"\"\"\n",
    "    A function that iterates through a dataset and removes rows with non-English index_col values.\n",
    "\n",
    "    Args:\n",
    "        dataset (list): The dataset to be checked.\n",
    "        index_col (int): The column to be checked for non-English characters\n",
    "        header (bool): If header is present, remove first row of dataset by default. If header is not present, continue.\n",
    "\n",
    "    Returns:\n",
    "        filtered_data (list): A list containing only apps with English names.\n",
    "    \"\"\"\n",
    "    if header:\n",
    "        dataset = dataset[1:]\n",
    "\n",
    "    filtered_data = []\n",
    "\n",
    "    for row in dataset:\n",
    "        name = row[index_col]\n",
    "\n",
    "        if is_english(name):\n",
    "            filtered_data.append(row)\n",
    "\n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "android_english = filter_english_apps(android_clean, 0)\n",
    "apple_english = filter_english_apps(apple, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of android list with only English apps: 9614\n",
      "Length of android list with only English apps: 7197\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of android list with only English apps: {len(android_english)}\")\n",
    "print(f\"Length of android list with only English apps: {len(apple_english)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Paid Apps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Android dataset, the `Price` column gives apps either as 'Free' (str) or as $3.99, for example. So I will need to remove the dollar symbol and convert to floats.\n",
    "\n",
    "In the Apple dataset, the `price` column gives apps as either 0.0 (float), which denotes free, or as 0.99, for example. There are no dollar signs.\n",
    "\n",
    "I will need to devise a function that is flexible enough to handle both cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_paid_apps(dataset, index_col, header=False, print_results=True):\n",
    "    \"\"\"\n",
    "    A function that iterates through a dataset and removes paid apps.\n",
    "\n",
    "    Args:\n",
    "        dataset (list): The dataset to be checked.\n",
    "        index_col (int): The column to be checked for prices.\n",
    "        header (bool): If header is present, remove first row of dataset by default. If header is not present, continue.\n",
    "        print_results (bool): Print before and after results.\n",
    "\n",
    "    Returns:\n",
    "        clean_data (list): A list containing only FREE apps.\n",
    "    \"\"\"\n",
    "    if header:\n",
    "        dataset = dataset[1:]\n",
    "\n",
    "    clean_data = []\n",
    "\n",
    "    for row in dataset:\n",
    "        check_val = row[index_col]\n",
    "        if '$' in check_val:\n",
    "            check_val = check_val.replace(\"$\", \"\")\n",
    "\n",
    "        if check_val == 'Free' or float(check_val) == 0.0:\n",
    "            clean_data.append(row)\n",
    "\n",
    "    print(f\"Number of rows before: {len(dataset)}\")\n",
    "    print(f\"Number of rows after: {len(clean_data)}\")\n",
    "    \n",
    "    return clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before: 9614\n",
      "Number of rows after: 8864\n",
      "Number of rows before: 7197\n",
      "Number of rows after: 4056\n"
     ]
    }
   ],
   "source": [
    "android_free_english = remove_paid_apps(android_english, 7)\n",
    "apple_free_english = remove_paid_apps(apple_english, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To minimize risks and overhead, we want to find app profiles that do well on both Android and Apple marketplaces. When we develop our app, there's three things we'd like to do:\n",
    "\n",
    "* Build a minimal Android version of the app, and add it to Google Play.\n",
    "* If the app has a good response from users, we develop it further.\n",
    "* If the app is profitable after six months, we build an iOS version of the app and add it to the App Store."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each dataset has specific columns that will be important to analyze. We'd like to know the `genre` for each app, for instance, so we can determine whether some categories are more popular than others in terms of downloads. We can also base our genre analysis on the number of reviews giving to the app, or only look at apps that are 4 stars+ with a set threshold number of reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to create two functions: One that generates frequency tables and spits out percentages. And another function that displays those returned percentages in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function named freq_table() that takes two inputs: dataset and index\n",
    "# The function should return a dictionary with the keys being the values in the index column and the values being the frequency of the key, as a percentage.\n",
    "def freq_table(dataset, index):\n",
    "    \"\"\"\n",
    "    A function that creates a frequency table of the values in a given column.\n",
    "\n",
    "    Args:\n",
    "        dataset (list): The dataset to be checked.\n",
    "        index (int): The column to be checked for values.\n",
    "\n",
    "    Returns:\n",
    "        dict_pct (dict): A dictionary containing each key and its value as a percentage.\n",
    "    \"\"\"\n",
    "    freq_dict = {}\n",
    "    dict_pct = {}\n",
    "\n",
    "    for row in dataset:\n",
    "        value = row[index]\n",
    "\n",
    "        if value in freq_dict:\n",
    "            freq_dict[value] += 1\n",
    "        else:\n",
    "            freq_dict[value] = 1\n",
    "\n",
    "    # Calculate the percentage of each key in freq_dict and add to dict_pct\n",
    "    for key in freq_dict:\n",
    "        dict_pct[key] = round((freq_dict[key] / sum(freq_dict.values())) * 100, 2)\n",
    "\n",
    "    return dict_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_table(dataset, index):\n",
    "    table = freq_table(dataset, index)\n",
    "    table_display = []\n",
    "    for key in table:\n",
    "        key_val_as_tuple = (table[key], key)\n",
    "        table_display.append(key_val_as_tuple)\n",
    "\n",
    "    table_sorted = sorted(table_display, reverse = True)\n",
    "    for entry in table_sorted:\n",
    "        print(entry[1], ':', entry[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing and Analyzing Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin by analyzing the `prime_genre` column for the Apple Store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Games : 55.65\n",
      "Entertainment : 8.23\n",
      "Photo & Video : 4.12\n",
      "Social Networking : 3.53\n",
      "Education : 3.25\n",
      "Shopping : 2.98\n",
      "Utilities : 2.69\n",
      "Lifestyle : 2.32\n",
      "Finance : 2.07\n",
      "Sports : 1.95\n",
      "Health & Fitness : 1.87\n",
      "Music : 1.65\n",
      "Book : 1.63\n",
      "Productivity : 1.53\n",
      "News : 1.43\n",
      "Travel : 1.38\n",
      "Food & Drink : 1.06\n",
      "Weather : 0.76\n",
      "Reference : 0.49\n",
      "Navigation : 0.49\n",
      "Business : 0.49\n",
      "Catalogs : 0.22\n",
      "Medical : 0.2\n"
     ]
    }
   ],
   "source": [
    "display_table(apple_free_english, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis**: Games are the most popular category, by far. This is followed by Enterntainment. At least two-thirds of all apps are designed for Entertainment, rather than practical purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tools : 8.45\n",
      "Entertainment : 6.07\n",
      "Education : 5.35\n",
      "Business : 4.59\n",
      "Productivity : 3.89\n",
      "Lifestyle : 3.89\n",
      "Finance : 3.7\n",
      "Medical : 3.53\n",
      "Sports : 3.46\n",
      "Personalization : 3.32\n",
      "Communication : 3.24\n",
      "Action : 3.1\n",
      "Health & Fitness : 3.08\n",
      "Photography : 2.94\n",
      "News & Magazines : 2.8\n",
      "Social : 2.66\n",
      "Travel & Local : 2.32\n",
      "Shopping : 2.25\n",
      "Books & Reference : 2.14\n",
      "Simulation : 2.04\n",
      "Dating : 1.86\n",
      "Arcade : 1.85\n",
      "Video Players & Editors : 1.77\n",
      "Casual : 1.76\n",
      "Maps & Navigation : 1.4\n",
      "Food & Drink : 1.24\n",
      "Puzzle : 1.13\n",
      "Racing : 0.99\n",
      "Role Playing : 0.94\n",
      "Libraries & Demo : 0.94\n",
      "Auto & Vehicles : 0.93\n",
      "Strategy : 0.91\n",
      "House & Home : 0.82\n",
      "Weather : 0.8\n",
      "Events : 0.71\n",
      "Adventure : 0.68\n",
      "Comics : 0.61\n",
      "Beauty : 0.6\n",
      "Art & Design : 0.6\n",
      "Parenting : 0.5\n",
      "Card : 0.45\n",
      "Casino : 0.43\n",
      "Trivia : 0.42\n",
      "Educational;Education : 0.39\n",
      "Board : 0.38\n",
      "Educational : 0.37\n",
      "Education;Education : 0.34\n",
      "Word : 0.26\n",
      "Casual;Pretend Play : 0.24\n",
      "Music : 0.2\n",
      "Racing;Action & Adventure : 0.17\n",
      "Puzzle;Brain Games : 0.17\n",
      "Entertainment;Music & Video : 0.17\n",
      "Casual;Brain Games : 0.14\n",
      "Casual;Action & Adventure : 0.14\n",
      "Arcade;Action & Adventure : 0.12\n",
      "Action;Action & Adventure : 0.1\n",
      "Educational;Pretend Play : 0.09\n",
      "Simulation;Action & Adventure : 0.08\n",
      "Parenting;Education : 0.08\n",
      "Entertainment;Brain Games : 0.08\n",
      "Board;Brain Games : 0.08\n",
      "Parenting;Music & Video : 0.07\n",
      "Educational;Brain Games : 0.07\n",
      "Casual;Creativity : 0.07\n",
      "Art & Design;Creativity : 0.07\n",
      "Education;Pretend Play : 0.06\n",
      "Role Playing;Pretend Play : 0.05\n",
      "Education;Creativity : 0.05\n",
      "Role Playing;Action & Adventure : 0.03\n",
      "Puzzle;Action & Adventure : 0.03\n",
      "Entertainment;Creativity : 0.03\n",
      "Entertainment;Action & Adventure : 0.03\n",
      "Educational;Creativity : 0.03\n",
      "Educational;Action & Adventure : 0.03\n",
      "Education;Music & Video : 0.03\n",
      "Education;Brain Games : 0.03\n",
      "Education;Action & Adventure : 0.03\n",
      "Adventure;Action & Adventure : 0.03\n",
      "Video Players & Editors;Music & Video : 0.02\n",
      "Sports;Action & Adventure : 0.02\n",
      "Simulation;Pretend Play : 0.02\n",
      "Puzzle;Creativity : 0.02\n",
      "Music;Music & Video : 0.02\n",
      "Entertainment;Pretend Play : 0.02\n",
      "Casual;Education : 0.02\n",
      "Board;Action & Adventure : 0.02\n",
      "Video Players & Editors;Creativity : 0.01\n",
      "Trivia;Education : 0.01\n",
      "Travel & Local;Action & Adventure : 0.01\n",
      "Tools;Education : 0.01\n",
      "Strategy;Education : 0.01\n",
      "Strategy;Creativity : 0.01\n",
      "Strategy;Action & Adventure : 0.01\n",
      "Simulation;Education : 0.01\n",
      "Role Playing;Brain Games : 0.01\n",
      "Racing;Pretend Play : 0.01\n",
      "Puzzle;Education : 0.01\n",
      "Parenting;Brain Games : 0.01\n",
      "Music & Audio;Music & Video : 0.01\n",
      "Lifestyle;Pretend Play : 0.01\n",
      "Lifestyle;Education : 0.01\n",
      "Health & Fitness;Education : 0.01\n",
      "Health & Fitness;Action & Adventure : 0.01\n",
      "Entertainment;Education : 0.01\n",
      "Communication;Creativity : 0.01\n",
      "Comics;Creativity : 0.01\n",
      "Casual;Music & Video : 0.01\n",
      "Card;Action & Adventure : 0.01\n",
      "Books & Reference;Education : 0.01\n",
      "Art & Design;Pretend Play : 0.01\n",
      "Art & Design;Action & Adventure : 0.01\n",
      "Arcade;Pretend Play : 0.01\n",
      "Adventure;Education : 0.01\n"
     ]
    }
   ],
   "source": [
    "display_table(android_free_english, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAMILY : 18.91\n",
      "GAME : 9.72\n",
      "TOOLS : 8.46\n",
      "BUSINESS : 4.59\n",
      "LIFESTYLE : 3.9\n",
      "PRODUCTIVITY : 3.89\n",
      "FINANCE : 3.7\n",
      "MEDICAL : 3.53\n",
      "SPORTS : 3.4\n",
      "PERSONALIZATION : 3.32\n",
      "COMMUNICATION : 3.24\n",
      "HEALTH_AND_FITNESS : 3.08\n",
      "PHOTOGRAPHY : 2.94\n",
      "NEWS_AND_MAGAZINES : 2.8\n",
      "SOCIAL : 2.66\n",
      "TRAVEL_AND_LOCAL : 2.34\n",
      "SHOPPING : 2.25\n",
      "BOOKS_AND_REFERENCE : 2.14\n",
      "DATING : 1.86\n",
      "VIDEO_PLAYERS : 1.79\n",
      "MAPS_AND_NAVIGATION : 1.4\n",
      "FOOD_AND_DRINK : 1.24\n",
      "EDUCATION : 1.16\n",
      "ENTERTAINMENT : 0.96\n",
      "LIBRARIES_AND_DEMO : 0.94\n",
      "AUTO_AND_VEHICLES : 0.93\n",
      "HOUSE_AND_HOME : 0.82\n",
      "WEATHER : 0.8\n",
      "EVENTS : 0.71\n",
      "PARENTING : 0.65\n",
      "ART_AND_DESIGN : 0.64\n",
      "COMICS : 0.62\n",
      "BEAUTY : 0.6\n"
     ]
    }
   ],
   "source": [
    "display_table(android_free_english, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Games : 55.65\n",
      "Entertainment : 8.23\n",
      "Photo & Video : 4.12\n",
      "Social Networking : 3.53\n",
      "Education : 3.25\n",
      "Shopping : 2.98\n",
      "Utilities : 2.69\n",
      "Lifestyle : 2.32\n",
      "Finance : 2.07\n",
      "Sports : 1.95\n",
      "Health & Fitness : 1.87\n",
      "Music : 1.65\n",
      "Book : 1.63\n",
      "Productivity : 1.53\n",
      "News : 1.43\n",
      "Travel : 1.38\n",
      "Food & Drink : 1.06\n",
      "Weather : 0.76\n",
      "Reference : 0.49\n",
      "Navigation : 0.49\n",
      "Business : 0.49\n",
      "Catalogs : 0.22\n",
      "Medical : 0.2\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
